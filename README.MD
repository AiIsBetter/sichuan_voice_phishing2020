## 2020首届数字四川创新大赛-算法赛道-诈骗电话识别
### 比赛地址：[诈骗电话识别](http://www.scdata.net.cn/common/cmpt/%E8%AF%88%E9%AA%97%E7%94%B5%E8%AF%9D%E8%AF%86%E5%88%AB_%E7%AB%9E%E8%B5%9B%E4%BF%A1%E6%81%AF.html)
### 比赛总结

工作之余参加的比赛，复赛的时候刚好赶上项目验收赶进度，遗憾只对一个表做了特征工程后提交了几次成绩，另外几个表还没来得及重新清理下提交成绩，浪费掉了获得更好名次的机会。不过参加比赛还是收获了很多，记录下方便以后查看。

##### 1.数据说明
初赛阶段：预测2020年4月的数据；

复赛阶段：预测2020年5月的数据；

决赛阶段：预测2020年6月的数据
数据字段描述如下：

注1：初赛的测试集中，不存在arpu_201908、arpu_201909……arpu_202003等字段，取而代之的是arpu_202004这1个字段。
    ![输入图片说明](https://github.com/AiIsBetter/sichuan_voice_phishing2020/blob/master/IMG/train_user.png)
    ![输入图片说明](https://github.com/AiIsBetter/sichuan_voice_phishing2020/blob/master/IMG/train_voc.png)
    ![输入图片说明](https://github.com/AiIsBetter/sichuan_voice_phishing2020/blob/master/IMG/train_sms.png)
    ![输入图片说明](https://github.com/AiIsBetter/sichuan_voice_phishing2020/blob/master/IMG/train_app.png)
    
2.数据分析：
本次比赛的初赛训练集数据到3月份，测试集数据为4月份，复赛中将初赛测试集数据作为新的训练数据，预测5月的测试集数据。具体的数据统计在html_初赛，html_复赛中，常规的对每一个数据表进行统计，统计每个表的每一列的相关统计特征，比如缺失值情况，数值类型，数值分布，方差等等，对数据有个整体的映象，同时查看是否有一些异常的情况，这些异常情况可能需要删除或者属于强特可以加以利用。比如在本次比赛中，'arpu_xx'字段，通过将所有正样本取出查看，可以发现绝大部分都是缺失的，通过在模型预测结果完毕后，增加后处理的方式，将缺失样本预测结果强制转换为1，可以使得线上成绩有明显的提升，复赛初赛都有效果。前期的数据分析主要就是这个作用，一方面了解数据概况，另一方面发现一些小异常，保证和其他选手在同一起跑线上面。在训练集样本的处理上，初赛中，基本做法就这2种方式：1.只取arpu3月份的数据作为特征训练模型，保证模型的时效性，训练的数据分布能够和测试数据保持一致。2.划窗的方式，每个月数据作为一个新样本，扩大训练样本集8倍。我选择了第一种方式，并且赛后线上成绩公布，我的分数基本上线上线下相同，没有抖动，因此成绩有所上升。第二种方法我也尝试了下，线下分数暴涨，线上降分，我觉得应该是划窗所得的样本，在train_user特征表中大部分特征是相同的，即便划窗也只是其他几个表里的特征有所变化，但是本次比赛最重要的特征就在用户基础特征表里面，划窗并没有提供更加丰富的特征信息，因此只是导致了线下过拟合，效果并不好。而在复赛中，新增加的4月份数据分布更是与前面的不同，因此复赛中我也只使用了4月份的数据训练，并且4月份的数据分布与5月份有差异，导致直接使用初赛的特征工程会过拟合，不过当时没有时间做过多处理，就只使用了voc表做了一些特征改善，因为这个表的数据分布基本上和5月份一致。后面复赛结果b榜抖动在一个百，小于前排一些选手的抖动也证明了这个问题。

3.特征工程
本次比赛最重要的应该就是特征工程了，小数据集的比赛，模型基本上就是树模型等传统机器学习模型为主，深度学习类的DNN，FFM等模型由于数据量太小，反而就不合适了。以下对4个表的模型所做特征工程进行总结：

train_user:
'city_name'对一些高风险地区，单独用onehot编码，比如是否等于'广安'，等于1，否为0；类别特征label encode。其他特征用原始值。

train_voc:
每月、天、小时电话量统计,每月、天电话类型统计，每月电话时长分段统计，每月、天加密号码电话统计，每月、天对端加密电话数量统计，地理、区县编码后做统计特征，每月的的地理变化统计，每个月的活跃天数，目前设定每日电话数量>20为活跃，最后10,20,50....等电话主、被叫的时间间隔趋势。最后的活跃特征和趋势特征对分数提升很大，我的单voc表的分数在初赛和复赛中都很高，所以这个表的特征信息应该还是充分挖掘了的，并且和模型目标业务需求也是切合的。

train_sms:
一次时间超过5人定义为一次群发时间，时间的定义使用periods设定的阈值，比如0秒，5秒内都算同一时间，多次统计;发送短信的数量统计;最后10,20,50....等间隔短信条数，发送、接收短信的间隔统计，趋势变化；上下行短信比例以及单独统计;每月，天，小时短信统计。

train_app:
类别特征label encode，busi_name统计长度，flow分段离散化。

一些特征因为没有时间没有过多尝试，也列在下面以作记录：
app表个人感觉很重要，但是一直没有挖掘到比较有用的特征，tf-idf，count vector都试过，没有明显作用。对app的busi_name字段，当做一个序列特征，理解成描述客户日常生活习惯的一句话，通过使用流量情况排序后，做w2v也没做出很好的效果，可能参数没有调整好，或者处理方式不正确。根据test数据，查找每个客户使用流量top n app，分别提取流量，分别计算总流量占比，新建0-n排序列，选择每个客户的top 0-n app名，然后编码。流量的rank特征。不知道有用没，线下容易过拟合，无法提交验证了。

3.模型
模型选择了lightgbm，训练使用五折交叉验证的方式，每一折通过遍历验证集预测结果不同百分位的预测值，获得一组阈值用于计算f1分数，选取最佳的f1分数时的阈值。然后五折取平均f1分数作为本地分数，阈值的平均值作为测试集预测结果的阈值，然后提交结果。

4.思考
这次比赛重点还是特征工程上面，有效的特征工程才能够带来实质的提升，反而模型参数和一些骚操作无法带来实质的效果，另外w2v还要好好学习下如何有效的和树模型配合使用。app表里面的序列特征应该是有办法好好挖掘下的，后面如果想到好办法再回来补充下。通过这次比赛，对于电话诈骗业务场景有了更多的认识，希望以后别被诈骗，最近接这种电话越来越多了。
附上模型训练后五折的特征重要性图片：

   ![输入图片说明](https://github.com/AiIsBetter/sichuan_voice_phishing2020/blob/master/IMG/importances.png)

